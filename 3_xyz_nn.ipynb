{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ecae99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import sys \n",
    "import os \n",
    "import importlib\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5505539c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Protein_Input_funcions as pif\n",
    "import ReadingFasta_JL as ReadingFasta\n",
    "import FixedClassificationModel_JL as FixedClassificationModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "281f7910",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'FixedClassificationModel_JL' from '/mnt/af3ff5c3-2943-4972-8c3a-6b98174779b7/Justice/Chaperone_Analysis/OR_ML/Rtp1s_RF/FixedClassificationModel_JL.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(FixedClassificationModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b095caa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = pd.read_csv('./AlphaFold/xyz_enhance_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70287c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts the data table of coordinates to list of list \n",
    "X = matrix.drop(['id', 'enhance'], axis=1).values.tolist()\n",
    "y = matrix['enhance'].tolist()\n",
    "feature = matrix.drop(['id', 'enhance'], axis=1).columns.tolist()\n",
    "\n",
    "\n",
    "if (y.count(1)/y.count(0) > 1.5) | (y.count(0)/y.count(1) > 1.5):\n",
    "    BALANCE = False\n",
    "else: \n",
    "    BALANCE = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "661d6499",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = .25, random_state = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "aee226f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 4}\n",
      "Best score: 0.72\n",
      "Best parameters: {'max_depth': None, 'max_features': 2}\n",
      "Best score: 0.62\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Run a quick grid search to see the optimal parameters to tune for \n",
    "Note that this is an estimate so the actualy RF result may differ\n",
    "But this should serve as a quick suggestion on where to start. \n",
    "\"\"\"\n",
    "FixedClassificationModel.RFC_gridsearch_nestimator(X,y,n_estimators=[2,3,4,5,10,15,100,200])\n",
    "FixedClassificationModel.RFC_gridsearch_max_depth_features(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6214f729",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 100, \n",
    "                             max_depth = None, max_features = 2, \n",
    "                             bootstrap = True, random_state = 18).fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c9cff1",
   "metadata": {},
   "source": [
    "Normally accuracy is not the metric we use to judge the performance of a classification model for reasons such as possible imbalances in data leading to high accuracy due to imbalanced predictions to one class. However, for simplicity reasons I included it above. I also included the F1 score, which measures the harmonic mean between precision and recall. The F1 score metric is able to penalize large differences between precision. Generally speaking, we would prefer to determine a classification’s performance by its precision, recall, or F1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "63848b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 0.6153846153846154\n",
      "fl_score: 0.7058823529411764\n"
     ]
    }
   ],
   "source": [
    "# Create our predictions\n",
    "prediction = clf.predict(x_test)\n",
    "\n",
    "# Create confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, f1_score, accuracy_score\n",
    "confusion_matrix(y_test, prediction)\n",
    "\n",
    "\"\"\"\n",
    "Accuracy is measured as the total number of (TP + TN)/(All Cases), \n",
    "while a F1 score is calculated by 2*((precision*recall)/(precision + recall)), \n",
    "with precision = TP/(TP+FP), and recall = TP/(TP+FN).\n",
    "\"\"\"\n",
    "print(\"accuracy_score: {}\".format(accuracy_score(y_test, prediction)))\n",
    "# Display F1 score\n",
    "print(\"fl_score: {}\".format(f1_score(y_test,prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "7b858f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the important feature into a dataframe for visualization \n",
    "feat_importance = pd.DataFrame({'aa_position':feature,\n",
    "              'Importance':clf.feature_importances_}).sort_values('Importance', ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d94c60af",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in ['_C_', '_CA_', '_N_', '_O_']:\n",
    "    feat_importance.loc[feat_importance['aa_position'].str.contains(i), 'aa'] = i\n",
    "for i in range(25,286):\n",
    "    feat_importance.loc[feat_importance['aa_position'].str.contains((str(i)+'_')), 'resid'] = i\n",
    "for i in ['x','y', 'z']:    \n",
    "    feat_importance.loc[feat_importance['aa_position'].str.contains(i), 'coord'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a4f373b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aa</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>_CA_</th>\n",
       "      <td>0.270529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_C_</th>\n",
       "      <td>0.243727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_N_</th>\n",
       "      <td>0.245010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>_O_</th>\n",
       "      <td>0.240734</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Importance\n",
       "aa              \n",
       "_CA_    0.270529\n",
       "_C_     0.243727\n",
       "_N_     0.245010\n",
       "_O_     0.240734"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_importance[['aa', 'Importance']].groupby('aa').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "2d558ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77.0</th>\n",
       "      <td>0.032866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66.0</th>\n",
       "      <td>0.029270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63.0</th>\n",
       "      <td>0.028139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67.0</th>\n",
       "      <td>0.023072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59.0</th>\n",
       "      <td>0.023069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90.0</th>\n",
       "      <td>0.006929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55.0</th>\n",
       "      <td>0.006393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76.0</th>\n",
       "      <td>0.006107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80.0</th>\n",
       "      <td>0.005886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86.0</th>\n",
       "      <td>0.005548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Importance\n",
       "resid            \n",
       "77.0     0.032866\n",
       "66.0     0.029270\n",
       "63.0     0.028139\n",
       "67.0     0.023072\n",
       "59.0     0.023069\n",
       "...           ...\n",
       "90.0     0.006929\n",
       "55.0     0.006393\n",
       "76.0     0.006107\n",
       "80.0     0.005886\n",
       "86.0     0.005548\n",
       "\n",
       "[66 rows x 1 columns]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_importance[['resid', 'Importance']].groupby('resid').sum()\\\n",
    "    .sort_values(by='Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865beb93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a682cdcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64174b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba5f6b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
